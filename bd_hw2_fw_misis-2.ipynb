{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a2b06d19-8478-4df4-bb2d-99dfa4f07aad",
      "metadata": {
        "id": "a2b06d19-8478-4df4-bb2d-99dfa4f07aad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'pyspark.sql.functions' from '/opt/conda/lib/python3.8/site-packages/pyspark/sql/functions.py'>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1e1909f1-a5fa-4393-8213-a0c8bca6525d",
      "metadata": {
        "id": "1e1909f1-a5fa-4393-8213-a0c8bca6525d"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    spark.stop()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    sc.stop()\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7aaf3b64-1c0f-40c4-98bd-bf384645612e",
      "metadata": {
        "id": "7aaf3b64-1c0f-40c4-98bd-bf384645612e"
      },
      "outputs": [],
      "source": [
        "## так как я взял инфру из первого дз, спарк там запущен в докер контейнере и к нему присосаны два слейва - его 2 ноды воркеров\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"spark://spark-master:7077\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", False) \\\n",
        "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
        "    .config(\"spark.sql.sources.bucketing.enabled\", True) \\\n",
        "    .config(\"spark.executor.memory\", \"1g\") \\\n",
        "    .config(\"spark.driver.memory\", \"2g\") \\\n",
        "    .appName(\"hw1\") \\\n",
        "    .getOrCreate()\n",
        "    # .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3\") \\"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72aced5b-7236-40fd-a381-f26807d4010b",
      "metadata": {
        "id": "72aced5b-7236-40fd-a381-f26807d4010b"
      },
      "source": [
        "- Параметры по памяти определить самостоятельно\n",
        "- Включение AQE или Auto Broadcast => не зачет"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02f9ece4-83c7-486a-84b6-192fca40d533",
      "metadata": {
        "id": "02f9ece4-83c7-486a-84b6-192fca40d533"
      },
      "source": [
        "# Задание 1\n",
        "\n",
        "В исходном файле представлена информация о сотрудниках, их подразделении и заработной плате.\n",
        "1. Использовать Spark-сессию, которую мы использовали на семинарах или в ДЗ №1\n",
        "2. Посчитать среднюю зарплату в каждом подразделении с применением Spark RDD\n",
        "3. При решении задачи необходимо использовать функцию `aggregateByKey`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "51fd39bc-4dbf-4deb-bab3-2a3ef7ee67ee",
      "metadata": {
        "id": "51fd39bc-4dbf-4deb-bab3-2a3ef7ee67ee"
      },
      "outputs": [],
      "source": [
        "spark\n",
        "\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f18763c6",
      "metadata": {
        "id": "f18763c6"
      },
      "source": [
        "### Решение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7ede4db9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1,Козлов Алексей,Design,121846',\n",
              " '2,Иванов Дмитрий,Operations,89891',\n",
              " '3,Васильев Роман,Sales,120380',\n",
              " '4,Александров Андрей,Security,178169',\n",
              " '5,Лебедев Дмитрий,Admin,61106']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# читаем employees.csv из смаунченной /data\n",
        "rdd = sc.textFile('file:///data/task1/employees.csv')\n",
        "rdd.take(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "d7bd521c",
      "metadata": {
        "id": "d7bd521c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Design', 121846),\n",
              " ('Operations', 89891),\n",
              " ('Sales', 120380),\n",
              " ('Security', 178169),\n",
              " ('Admin', 61106)]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# 3. парсим строку в (department, salary)\n",
        "def parse_line(line: str):\n",
        "    parts = line.split(\",\")\n",
        "    # ожидаем ровно 4 поля: id, ФИО, департамент, зарплата\n",
        "    dept = parts[2].strip()\n",
        "    salary = int(parts[3].strip())   # ВАЖНО: квадратные скобки!\n",
        "    return (dept, salary)\n",
        "\n",
        "dept_salary_rdd = rdd.map(parse_line)\n",
        "\n",
        "dept_salary_rdd.take(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ecaee4ae",
      "metadata": {
        "id": "ecaee4ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Design', 128973.73214285714),\n",
              " ('Sales', 120917.60869565218),\n",
              " ('Security', 123997.92537313433),\n",
              " ('Admin', 127531.125),\n",
              " ('R&D', 119201.8),\n",
              " ('Product', 128217.5076923077),\n",
              " ('Legal', 125467.89333333333),\n",
              " ('Finance', 128928.08474576271),\n",
              " ('QA', 117809.54838709677),\n",
              " ('Support', 120634.5375),\n",
              " ('IT', 124254.38888888889),\n",
              " ('Marketing', 130941.44155844155),\n",
              " ('Operations', 125065.85483870968),\n",
              " ('HR', 125414.59154929577),\n",
              " ('Logistics', 122105.28301886792)]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zero_value = (0, 0)\n",
        "\n",
        "\n",
        "## reduce внутри партиции, acc - сюда считаем N зарплат внутри партиции и делаем count + 1, salary - новое значение \n",
        "def seq_op(acc, salary):\n",
        "    s, c = acc\n",
        "    return (s + salary, c + 1)\n",
        "\n",
        "\n",
        "## с разных партиций собираем данные\n",
        "def comb_op(acc1, acc2):\n",
        "    s1, c1 = acc1\n",
        "    s2, c2 = acc2\n",
        "    return (s1 + s2, c1 + c2)\n",
        "\n",
        "sum_count_by_dept = dept_salary_rdd.aggregateByKey(\n",
        "    zero_value,\n",
        "    seq_op,\n",
        "    comb_op\n",
        ")  \n",
        "\n",
        "\n",
        "avg_salary_by_dept = sum_count_by_dept.mapValues(\n",
        "    lambda sc_pair: sc_pair[0] / sc_pair[1]  # sum / count\n",
        ")\n",
        "\n",
        "\n",
        "avg_salary_by_dept.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40f06364",
      "metadata": {
        "id": "40f06364"
      },
      "source": [
        "# Задание 2\n",
        "\n",
        "## Входные данные\n",
        "\n",
        "Таблица `transactions` - информация о длительности просмотра контента пользователями:\n",
        "1. user_uid — уникальный идентификатор пользователя\n",
        "2. element_uid — уникальный идентификатор контента\n",
        "3. watched_time — время просмотра в секундах\n",
        "\n",
        "Справочник `catalogue` - каталог с описанием контента и метаинформации по нему\n",
        "\n",
        "P.S. Как вы можете заметить при просмотре данных по пользователями, нужный нам ключ для операции будет перекошен (90% строк представлены на фильм, очень популярный среди смотревших) - это нужно доказать, то есть описать проблему в датасетах с точки зрения обработки Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0740055d",
      "metadata": {
        "id": "0740055d"
      },
      "source": [
        "### Решение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5e2e8c69",
      "metadata": {
        "id": "5e2e8c69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-----------+------------+\n",
            "|user_uid|element_uid|watched_time|\n",
            "+--------+-----------+------------+\n",
            "|  408794|       2714|        7583|\n",
            "|  247546|       2714|        4450|\n",
            "|   43556|       2714|        7569|\n",
            "|  517299|       2714|           1|\n",
            "|  143593|       2714|        7284|\n",
            "+--------+-----------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- user_uid: integer (nullable = true)\n",
            " |-- element_uid: integer (nullable = true)\n",
            " |-- watched_time: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transactions = spark.read \\\n",
        "    .option(\"header\", True) \\\n",
        "    .option(\"inferSchema\", True) \\\n",
        "    .csv(\"file:///data/task2/skew_transactions.csv\")\n",
        "\n",
        "transactions.show(5)\n",
        "transactions.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe5bfd57",
      "metadata": {},
      "source": [
        "Показываем явный перекос, ключ 2714 встречается очень много раз\n",
        "ну ещё можно догадаться какую оптимизацию нужно использовать из этой строки     .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36ad2ca8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------+\n",
            "|element_uid|   count|\n",
            "+-----------+--------+\n",
            "|       2714|20496000|\n",
            "|        747|   61272|\n",
            "|       2639|   61119|\n",
            "|       3783|   55228|\n",
            "|       2245|   52942|\n",
            "|       6127|   52168|\n",
            "|      10061|   48993|\n",
            "|       3916|   48243|\n",
            "|       8771|   47480|\n",
            "|       3336|   45646|\n",
            "+-----------+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transactions.groupBy(\"element_uid\").count().orderBy(F.desc(\"count\")).show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dde95359",
      "metadata": {
        "id": "dde95359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- element_uid: integer (nullable = false)\n",
            " |-- type: string (nullable = true)\n",
            " |-- availability: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- feature_1: double (nullable = true)\n",
            " |-- feature_2: double (nullable = true)\n",
            " |-- feature_3: double (nullable = true)\n",
            " |-- feature_4: double (nullable = true)\n",
            " |-- feature_5: double (nullable = true)\n",
            " |-- attributes: array (nullable = true)\n",
            " |    |-- element: integer (containsNull = true)\n",
            "\n",
            "+-----------+-----+------------------------------+--------+--------------------+------------+---------+------------+------------+-------------------------------------------------------------------------------------------+\n",
            "|element_uid|type |availability                  |duration|feature_1           |feature_2   |feature_3|feature_4   |feature_5   |attributes                                                                                 |\n",
            "+-----------+-----+------------------------------+--------+--------------------+------------+---------+------------+------------+-------------------------------------------------------------------------------------------+\n",
            "|1983       |movie|[purchase, rent, subscription]|140     |1657223.396513469   |0.7536096584|39.0     |1.1194091265|0.0         |[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]|\n",
            "|3783       |movie|[purchase, rent, subscription]|110     |3.5565207694893226E7|0.7662537759|41.0     |1.1386044027|0.6547073468|[1, 26, 27, 28, 29, 7, 30, 31, 32, 10, 14, 15, 33, 19, 20, 21, 34, 35, 36, 37, 25]         |\n",
            "|5208       |movie|[purchase, rent, subscription]|90      |1.327067652431015E7 |0.7654246597|27.0     |1.1318073548|0.5927161087|[1, 38, 39, 40, 7, 41, 42, 43, 14, 15, 17, 18, 19, 20, 21, 44, 45, 46, 25]                 |\n",
            "|9744       |movie|[purchase, rent, subscription]|120     |2.1749917409822803E7|0.7578744427|26.0     |1.1335254517|0.6547073468|[1, 47, 48, 49, 50, 51, 52, 53, 32, 42, 54, 14, 15, 17, 18, 19, 20, 21, 55, 56, 57, 58, 25]|\n",
            "|1912       |movie|[purchase, rent]              |110     |9212963.985682394   |0.7595661572|7.0      |1.1101274384|0.6547073468|[1, 59, 60, 61, 62, 7, 52, 63, 10, 42, 54, 17, 18, 19, 20, 64, 65]                         |\n",
            "+-----------+-----+------------------------------+--------+--------------------+------------+---------+------------+------------+-------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pyspark.sql.types import (\n",
        "    StructType, StructField,\n",
        "    IntegerType, StringType, ArrayType, DoubleType\n",
        ")\n",
        "\n",
        "# 1. Читаем JSON в Python (он небольшой, 2.8 МБ)\n",
        "with open(\"/data/task2/catalogue.json\", \"r\") as f:\n",
        "    raw = json.load(f)   # dict: {\"1983\": {...}, \"3783\": {...}, ...}\n",
        "\n",
        "# 2. Готовим строки с ОДНОЗНАЧНЫМИ типами\n",
        "rows = []\n",
        "for element_id_str, payload in raw.items():\n",
        "    # ключ — это element_uid\n",
        "    element_id = int(element_id_str)\n",
        "\n",
        "    # защитно достаём значения, приводим к нужным типам\n",
        "    t = payload.get(\"type\")\n",
        "\n",
        "    availability = payload.get(\"availability\")\n",
        "    if availability is not None:\n",
        "        availability = [str(x) for x in availability]\n",
        "\n",
        "    duration = payload.get(\"duration\")\n",
        "    duration = int(duration) if duration is not None else None\n",
        "\n",
        "    def as_float(name):\n",
        "        val = payload.get(name)\n",
        "        return float(val) if val is not None else None\n",
        "\n",
        "    feature_1 = as_float(\"feature_1\")\n",
        "    feature_2 = as_float(\"feature_2\")\n",
        "    feature_3 = as_float(\"feature_3\")\n",
        "    feature_4 = as_float(\"feature_4\")\n",
        "    feature_5 = as_float(\"feature_5\")\n",
        "\n",
        "    attributes = payload.get(\"attributes\")\n",
        "    if attributes is not None:\n",
        "        attributes = [int(x) for x in attributes]\n",
        "\n",
        "    row = {\n",
        "        \"element_uid\": element_id,\n",
        "        \"type\": t,\n",
        "        \"availability\": availability,\n",
        "        \"duration\": duration,\n",
        "        \"feature_1\": feature_1,\n",
        "        \"feature_2\": feature_2,\n",
        "        \"feature_3\": feature_3,\n",
        "        \"feature_4\": feature_4,\n",
        "        \"feature_5\": feature_5,\n",
        "        \"attributes\": attributes,\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "# 3. Явная схема\n",
        "schema = StructType([\n",
        "    StructField(\"element_uid\", IntegerType(), False),\n",
        "    StructField(\"type\", StringType(), True),\n",
        "    StructField(\"availability\", ArrayType(StringType()), True),\n",
        "    StructField(\"duration\", IntegerType(), True),\n",
        "    StructField(\"feature_1\", DoubleType(), True),\n",
        "    StructField(\"feature_2\", DoubleType(), True),\n",
        "    StructField(\"feature_3\", DoubleType(), True),\n",
        "    StructField(\"feature_4\", DoubleType(), True),\n",
        "    StructField(\"feature_5\", DoubleType(), True),\n",
        "    StructField(\"attributes\", ArrayType(IntegerType()), True),\n",
        "])\n",
        "\n",
        "# 4. Создаём DataFrame с заданной схемой\n",
        "catalogue = spark.createDataFrame(rows, schema=schema)\n",
        "\n",
        "catalogue.printSchema()\n",
        "catalogue.show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "df30c61d",
      "metadata": {
        "id": "df30c61d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------+------------+------+------------------------------+--------+--------------------+------------+---------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|element_uid|user_uid|watched_time|type  |availability                  |duration|feature_1           |feature_2   |feature_3|feature_4   |feature_5   |attributes                                                                                                                             |\n",
            "+-----------+--------+------------+------+------------------------------+--------+--------------------+------------+---------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|4101       |234775  |4506        |movie |[purchase, rent, subscription]|80      |3.7477159218975045E7|0.6773504396|16.0     |1.1386044027|0.6547073468|[11701, 11702, 11703, 11705, 83, 571, 11706, 43, 14, 15, 18, 19, 20, 21, 55, 44, 25]                                                   |\n",
            "|8592       |204176  |6423        |movie |[purchase, rent]              |110     |2.099439646910964E7 |0.7268892362|17.0     |1.1335254517|0.5927161087|[10524, 5142, 658, 729, 1196, 7, 10525, 31, 9, 42, 17, 18, 19, 20, 35, 36, 6161, 10526, 2045, 25]                                      |\n",
            "|6866       |3541    |17779       |series|[]                            |20      |4.175615927932044E7 |0.7314842061|0.0      |1.1283323575|0.6547073468|[34508, 34509, 15676, 17779, 270, 34240, 43, 25]                                                                                       |\n",
            "|4291       |517205  |18          |movie |[purchase, rent, subscription]|90      |2.3400984544383574E7|0.6356729355|12.0     |1.1352308688|0.6804096966|[1238, 605, 3929, 8621, 1139, 7, 31393, 32, 42, 43, 14, 15, 17, 19, 20, 151, 21, 31394, 31395, 31396, 25]                              |\n",
            "|7726       |56407   |6058        |movie |[purchase, rent, subscription]|110     |1.685936244961082E7 |0.7553217061|24.0     |1.1318073548|0.4496666915|[9937, 9938, 9939, 9940, 9941, 245, 246, 247, 51, 52, 1320, 1321, 10, 14, 15, 17, 19, 20, 21, 700, 9942, 9943, 25]                     |\n",
            "|950        |504955  |12          |movie |[purchase, rent, subscription]|90      |1.1129883357378954E7|0.7346657673|12.0     |1.1248043047|0.6547073468|[10957, 505, 1652, 23492, 7, 51, 7812, 130, 31, 54, 14, 15, 239, 17, 20, 21, 700, 4558, 23493, 132, 25]                                |\n",
            "|3013       |193729  |459         |movie |[]                            |100     |3.362920058818847E7 |0.6166515975|0.0      |1.1386044027|0.6804096966|[9260, 17864, 17865, 17866, 17867, 7, 17868, 10, 42, 54, 17869, 25]                                                                    |\n",
            "|5401       |165581  |3976        |movie |[purchase, rent, subscription]|70      |3.598502758002251E7 |0.6077165889|19.0     |1.140272879 |-1.0        |[14401, 14402, 2469, 13112, 270, 9701, 43, 14, 15, 17, 18, 19, 272, 20, 44, 25]                                                        |\n",
            "|6522       |255519  |1547        |movie |[purchase, rent, subscription]|100     |3196355.7387515837  |0.7804592868|20.0     |1.1043740383|0.5927161087|[612, 5570, 5571, 3356, 1037, 5572, 5573, 7, 5574, 123, 32, 42, 5237, 5575, 5576, 14, 15, 17, 18, 19, 20, 21, 56, 5577, 188]           |\n",
            "|8473       |512851  |193         |movie |[purchase, rent, subscription]|110     |1.7069745354718123E7|0.7620887549|10.0     |1.1082255103|0.6547073468|[14681, 4518, 7515, 3319, 1887, 7, 2166, 42, 54, 14, 15, 239, 17, 20, 21, 700, 6263]                                                   |\n",
            "|2575       |323007  |5605        |movie |[purchase, rent, subscription]|90      |3.418888491432931E7 |0.6643603587|27.0     |1.1386044027|0.6804096966|[3471, 821, 16455, 155, 798, 83, 7, 24607, 31, 54, 14, 15, 17, 18, 19, 20, 21, 24608, 24609, 4548, 25]                                 |\n",
            "|5724       |367234  |8299        |series|[]                            |20      |4.185186273565136E7 |0.7620887549|2.0      |1.1283323575|0.6547073468|[4773, 6421, 24804, 24034, 270, 34399, 34400, 20089, 43, 25]                                                                           |\n",
            "|283        |331361  |4964        |movie |[purchase, rent, subscription]|100     |3.940810730261171E7 |0.7117737478|18.0     |1.140272879 |0.6547073468|[1043, 1044, 1045, 1046, 52, 1047, 42, 175, 14, 15, 131, 17, 18, 19, 21, 25]                                                           |\n",
            "|9932       |289307  |18588       |movie |[purchase, rent]              |220     |4.363376518826398E7 |0.7400546   |26.0     |1.1419293948|0.5927161087|[3862, 3099, 3863, 3864, 3123, 7, 522, 31, 32, 10, 131, 170, 33, 34, 35, 36, 3838, 25]                                                 |\n",
            "|9491       |395743  |5715        |movie |[purchase, rent, subscription]|100     |4.153604845537203E7 |0.7198836614|36.0     |1.1419293948|0.6547073468|[604, 605, 606, 552, 83, 7, 52, 553, 31, 42, 54, 175, 14, 15, 131, 17, 18, 19, 21, 361, 25]                                            |\n",
            "|4962       |135984  |909         |series|[purchase, subscription]      |40      |4.045158024434441E7 |0.74050001  |11.0     |1.1335254517|0.4496666915|[35265, 577, 35266, 1134, 14, 15, 1135, 25]                                                                                            |\n",
            "|1521       |91419   |6372        |movie |[purchase, rent, subscription]|110     |4.216482660890673E7 |0.7184658551|38.0     |1.1419293948|0.5927161087|[3704, 6634, 6635, 4389, 270, 6636, 130, 42, 14, 15, 131, 17, 18, 19, 328, 272, 25]                                                    |\n",
            "|8647       |154797  |505         |movie |[purchase, rent, subscription]|90      |4.30304262817811E7  |0.6883405989|20.0     |1.1419293948|0.6804096966|[17998, 30010, 17846, 14523, 270, 30011, 130, 31, 42, 14, 15, 131, 17, 18, 19, 272, 4861, 25]                                          |\n",
            "|937        |558399  |847         |movie |[purchase, rent, subscription]|80      |2.342896909267939E7 |0.7342129952|13.0     |1.1335254517|0.6547073468|[7805, 801, 5694, 7806, 7807, 7, 52, 7808, 42, 14, 15, 17, 18, 19, 20, 21, 995, 25]                                                    |\n",
            "|3501       |574494  |649         |movie |[purchase, rent, subscription]|100     |3.3531255640827574E7|0.7484235682|27.0     |1.1386044027|0.6547073468|[4517, 4518, 2470, 4519, 1036, 519, 7, 4520, 42, 14, 15, 17, 18, 19, 20, 21, 4521, 25]                                                 |\n",
            "|5715       |233367  |39          |movie |[rent, subscription]          |110     |1.6925582387847964E7|0.7561746531|40.0     |1.1318073548|0.6547073468|[1625, 1230, 4749, 1777, 626, 7, 5096, 123, 42, 43, 14, 15, 17, 20, 21, 44, 56, 5098, 25]                                              |\n",
            "|10061      |319197  |5435        |movie |[purchase, rent, subscription]|100     |4.156312319248322E7 |0.6643603587|26.0     |1.1419293948|0.6547073468|[2023, 6343, 1087, 2461, 7, 3472, 31, 54, 14, 15, 131, 17, 18, 19, 21, 25]                                                             |\n",
            "|5741       |67519   |773         |series|[subscription]                |40      |3.671941298180621E7 |0.7536096584|6.0      |1.1369237919|0.6804096966|[1379, 19984, 33531, 16082, 52, 15384, 33514, 33532, 308, 42, 54, 175, 15, 202, 25]                                                    |\n",
            "|6784       |296907  |6159        |movie |[purchase, rent, subscription]|110     |3.9701949270307094E7|0.7475518292|28.0     |1.140272879 |0.6804096966|[6330, 3846, 6331, 713, 7, 894, 31, 42, 54, 43, 14, 15, 131, 170, 33, 17, 21, 284, 25]                                                 |\n",
            "|3137       |258766  |7450        |movie |[purchase, rent, subscription]|130     |3.570365867345919E7 |0.7788641879|31.0     |1.1386044027|0.6804096966|[4012, 5599, 1174, 8299, 342, 7, 8964, 130, 42, 124, 14, 15, 17, 18, 19, 20, 21, 25]                                                   |\n",
            "|6818       |527507  |2136        |movie |[purchase, rent, subscription]|80      |1.6471345793399198E7|0.7887183095|13.0     |1.1300763881|0.0         |[79, 52, 29246, 29247, 1134, 11, 14, 15, 1135, 17, 19, 20, 44, 700, 12058, 29248, 71, 25]                                              |\n",
            "|4290       |199828  |1401        |movie |[purchase, rent, subscription]|80      |4.077936182920017E7 |0.6427716137|25.0     |1.140272879 |0.6547073468|[4819, 798, 3064, 724, 7, 1647, 31, 43, 14, 15, 131, 170, 33, 17, 21, 44, 25]                                                          |\n",
            "|5840       |50632   |5379        |movie |[purchase, rent, subscription]|110     |4.216482660890673E7 |0.7069154837|24.0     |1.140272879 |0.6547073468|[1207, 1834, 11521, 1084, 2228, 7, 52, 11522, 123, 42, 124, 14, 15, 131, 17, 18, 19, 21, 58, 25]                                       |\n",
            "|7750       |371204  |4253        |movie |[purchase, rent, subscription]|80      |6680391.677090588   |0.6604805746|20.0     |1.1230198714|0.5927161087|[1213, 1732, 1733, 1734, 1735, 7, 1736, 31, 32, 10, 11, 43, 14, 15, 17, 18, 19, 20, 22, 1737, 1738, 1739, 24, 25]                      |\n",
            "|1022       |243776  |10042       |movie |[purchase, rent]              |130     |1601254.9477048104  |0.8171022975|11.0     |1.0984737271|0.5927161087|[4690, 516, 2179, 4695, 4696, 4697, 3026, 4698, 4699, 4700, 3142, 7, 387, 42, 4701, 4702, 4703, 4704, 17, 19, 20, 151, 2372, 4705, 489]|\n",
            "|1717       |376078  |7816        |movie |[purchase, rent, subscription]|140     |1615247.0599069751  |0.7732243944|28.0     |1.1063077983|0.5927161087|[4760, 1139, 1718, 2025, 39, 21073, 7, 2033, 31, 32, 10, 42, 1418, 21074, 14, 15, 17, 18, 19, 20, 21, 56, 665, 8015, 689]              |\n",
            "|434        |430807  |1551        |movie |[purchase, rent, subscription]|110     |4.048552293847391E7 |0.7212958453|9.0      |1.140272879 |0.6547073468|[9392, 16101, 12755, 20759, 192, 83, 571, 13617, 13618, 43, 14, 15, 17, 18, 19, 20, 21, 361, 25]                                       |\n",
            "|8505       |379199  |5020        |movie |[purchase, rent, subscription]|100     |4.361976611239486E7 |0.7703706452|11.0     |1.1352308688|0.5927161087|[678, 31735, 31736, 31737, 342, 31738, 1134, 14, 15, 1135, 17, 18, 19, 20, 25]                                                         |\n",
            "|4563       |412834  |7304        |movie |[subscription]                |60      |4.169757961735035E7 |0.7683181598|11.0     |1.1212215513|0.0         |[29877, 52, 29878, 1134, 14, 15, 1135, 71]                                                                                             |\n",
            "|9089       |145734  |1034        |movie |[purchase, rent, subscription]|100     |1.917537718580314E7 |0.7658394591|23.0     |1.1335254517|0.4496666915|[338, 1982, 8785, 1643, 484, 7, 8786, 11, 1492, 14, 15, 16, 33, 20, 388, 34, 35, 36, 8787, 8788, 8789, 1704, 1705, 25]                 |\n",
            "|6507       |86890   |5167        |movie |[purchase, rent, subscription]|90      |3.35592398652319E7  |0.7278129857|16.0     |1.1386044027|0.6804096966|[14388, 14389, 5692, 482, 2871, 7, 14390, 14391, 32, 10, 42, 43, 14, 15, 17, 18, 19, 20, 21, 55, 14392, 14393, 25]                     |\n",
            "|5810       |564649  |6254        |movie |[purchase, rent, subscription]|110     |2.4055905599223778E7|0.7505936251|15.0     |1.1352308688|0.5927161087|[8562, 5314, 1408, 8299, 177, 7, 1382, 42, 14, 15, 17, 18, 19, 20, 21, 56, 18148, 12126, 7258, 25]                                     |\n",
            "|7079       |248422  |5308        |movie |[purchase, rent, subscription]|90      |4.175902312784108E7 |0.6272082361|18.0     |1.1419293948|0.6547073468|[5599, 1415, 10128, 473, 7, 336, 52, 29441, 32, 54, 14, 15, 131, 17, 18, 19, 21, 25]                                                   |\n",
            "|8171       |392359  |3486        |movie |[subscription]                |100     |2.05163052667051E7  |0.7458019228|9.0      |1.1318073548|0.6804096966|[1015, 6710, 6738, 28504, 28505, 270, 21070, 42, 43, 328, 21071, 25]                                                                   |\n",
            "|9633       |181183  |7041        |movie |[purchase, rent, subscription]|120     |1.7664253683722306E7|0.7620887549|28.0     |1.1335254517|0.5927161087|[613, 691, 400, 557, 5265, 714, 7, 8882, 31, 32, 10, 14, 15, 33, 19, 20, 21, 34, 35, 36, 2719, 14641, 8884, 37, 25]                    |\n",
            "|7089       |238833  |251         |series|[purchase, subscription]      |40      |4.292020050288517E7 |0.6929487826|10.0     |1.140272879 |0.5927161087|[33424, 28502, 33425, 31096, 270, 33426, 123, 175, 14, 15, 32811, 25]                                                                  |\n",
            "|413        |375546  |4481        |movie |[purchase, rent, subscription]|80      |3.1432490309249174E7|0.6709146277|22.0     |1.1386044027|0.5927161087|[12370, 17905, 30197, 12428, 30198, 270, 30199, 130, 42, 14, 15, 17, 18, 19, 272, 20, 56, 30200, 30201, 25]                            |\n",
            "|2360       |85065   |5056        |movie |[purchase, rent, subscription]|90      |4.136722552436576E7 |0.6773504396|12.0     |1.140272879 |0.6804096966|[2450, 310, 8588, 5600, 503, 52, 8589, 31, 42, 54, 14, 15, 131, 17, 18, 19, 21, 25]                                                    |\n",
            "|546        |468554  |5382        |movie |[purchase, rent, subscription]|90      |4.3186059217850685E7|0.5870959603|27.0     |1.1419293948|0.6547073468|[6880, 20374, 6588, 1652, 714, 7, 4568, 31, 54, 14, 15, 131, 17, 18, 19, 21, 132, 25]                                                  |\n",
            "|2714       |408794  |7583        |movie |[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001  |45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]                                                  |\n",
            "|2714       |247546  |4450        |movie |[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001  |45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]                                                  |\n",
            "|2714       |43556   |7569        |movie |[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001  |45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]                                                  |\n",
            "|2714       |517299  |1           |movie |[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001  |45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]                                                  |\n",
            "|2714       |143593  |7284        |movie |[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001  |45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]                                                  |\n",
            "|2714       |379966  |7524        |movie |[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001  |45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]                                                  |\n",
            "+-----------+--------+------------+------+------------------------------+--------+--------------------+------------+---------+------------+------------+---------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Здесь необходимо вывести результат:\n",
        "# базовый join\n",
        "joined_plain = (\n",
        "    transactions.alias(\"t\")\n",
        "    .join(catalogue.alias(\"c\"), on=\"element_uid\", how=\"left\")\n",
        ")\n",
        "\n",
        "joined_plain.show(50, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "108c868f",
      "metadata": {
        "id": "108c868f"
      },
      "source": [
        "### Решение с оптимизацией"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6445a89e",
      "metadata": {
        "id": "6445a89e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Physical Plan ==\n",
            "*(2) Project [element_uid#92, user_uid#91, watched_time#93, type#329, availability#330, duration#331, feature_1#332, feature_2#333, feature_3#334, feature_4#335, feature_5#336, attributes#337]\n",
            "+- *(2) BroadcastHashJoin [element_uid#92], [element_uid#328], LeftOuter, BuildRight, false\n",
            "   :- FileScan csv [user_uid#91,element_uid#92,watched_time#93] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/data/task2/skew_transactions.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<user_uid:int,element_uid:int,watched_time:int>\n",
            "   +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=323]\n",
            "      +- *(1) Scan ExistingRDD[element_uid#328,type#329,availability#330,duration#331,feature_1#332,feature_2#333,feature_3#334,feature_4#335,feature_5#336,attributes#337]\n",
            "\n",
            "\n",
            "+-----------+--------+------------+-----+------------------------------+--------+--------------------+----------+---------+------------+------------+-------------------------------------------------------------------------------------+\n",
            "|element_uid|user_uid|watched_time|type |availability                  |duration|feature_1           |feature_2 |feature_3|feature_4   |feature_5   |attributes                                                                           |\n",
            "+-----------+--------+------------+-----+------------------------------+--------+--------------------+----------+---------+------------+------------+-------------------------------------------------------------------------------------+\n",
            "|2714       |408794  |7583        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |247546  |4450        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |43556   |7569        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |517299  |1           |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |143593  |7284        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |379966  |7524        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |445584  |7121        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |244115  |7360        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |563168  |2745        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |33751   |6822        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |300388  |6830        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |484030  |7145        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |22141   |7206        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |272816  |6233        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |416911  |188         |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |586681  |5247        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |197421  |6993        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |8339    |249         |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |93549   |0           |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "|2714       |58689   |7664        |movie|[purchase, rent, subscription]|130     |4.2346730221473105E7|0.74050001|45.0     |1.1419293948|0.5927161087|[4052, 4123, 4124, 4125, 270, 4126, 1241, 42, 14, 15, 131, 170, 33, 17, 328, 272, 25]|\n",
            "+-----------+--------+------------+-----+------------------------------+--------+--------------------+----------+---------+------------+------------+-------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ваше решение в ячейках ниже ...\n",
        "\n",
        "# оптимизированный join с broadcast\n",
        "joined_optimized = (\n",
        "    transactions.alias(\"t\")\n",
        "    .join(F.broadcast(catalogue).alias(\"c\"), on=\"element_uid\", how=\"left\")\n",
        ")\n",
        "\n",
        "joined_optimized.explain()\n",
        "joined_optimized.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01898809",
      "metadata": {
        "id": "01898809"
      },
      "source": [
        "# Задание 3\n",
        "\n",
        "## Входные данные\n",
        "\n",
        "Таблица `transactions`  — информация о длительности просомтра контента пользователями:\n",
        "\n",
        "1. user_uid — уникальный идентификатор пользователя\n",
        "2. element_uid — уникальный идентификатор контента\n",
        "3. watched_time — время просмотра в секундах\n",
        "\n",
        "Таблица `ratings`  — информация об оценках, поставленных пользователями:\n",
        "\n",
        "1. user_uid — уникальный идентификатор пользователя\n",
        "2. element_uid — уникальный идентификатор контента\n",
        "3. rating — поставленный пользователем рейтинг\n",
        "\n",
        "Справочник `user_uids`  — выборка пользователей:\n",
        "1. user_uid — уникальный идентификатор пользователя\n",
        "\n",
        "\n",
        "## Что нужно сделать\n",
        "Для каждого пользователя из выборки посчитать:\n",
        "1. Максимальное и минимальное время просмотра фильмов с оценками 8, 9 и 10\n",
        "2. Название фичи должно быть в формате `feat_<агрегирующая_функция>_watched_time_rating_<оценка>`\n",
        "3. Если у пользователь не ставил оценки 8, 9 и 10 то значение фичей должно быть null\n",
        "4. Описать принятые при разработки кода решения и возможные оптимизации\n",
        "\n",
        "Важно: сокращаем затраты на shuflle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5038c13c",
      "metadata": {},
      "source": [
        "## Перед выполнением всех join-ов, мы фильтруем оценки + делаем pivot для таблицы с оценкам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1cb99364",
      "metadata": {
        "id": "1cb99364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-----------+------------+\n",
            "|user_uid|element_uid|watched_time|\n",
            "+--------+-----------+------------+\n",
            "|  563180|       6130|        3264|\n",
            "|  133315|       2771|       10557|\n",
            "|  290104|        984|        6845|\n",
            "|  385385|       6980|        2734|\n",
            "|  408794|       2714|        7583|\n",
            "+--------+-----------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------+-----------+------+\n",
            "|user_uid|element_uid|rating|\n",
            "+--------+-----------+------+\n",
            "|  571252|       1364|    10|\n",
            "|   63140|       3037|    10|\n",
            "|  443817|       4363|     8|\n",
            "|  359870|       1364|    10|\n",
            "|  359870|       3578|     9|\n",
            "+--------+-----------+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------+\n",
            "|user_uid|\n",
            "+--------+\n",
            "|  110138|\n",
            "|  412991|\n",
            "|   83691|\n",
            "|  334052|\n",
            "|   24124|\n",
            "+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "transactions = (\n",
        "    spark.read\n",
        "    .option(\"header\", True)\n",
        "    .csv(\"file:///data/task3/cut_transactions.csv\")\n",
        "    .select(\n",
        "        F.col(\"user_uid\").cast(\"long\"),\n",
        "        F.col(\"element_uid\").cast(\"long\"),\n",
        "        F.col(\"watched_time\").cast(\"long\"),\n",
        "    )\n",
        ")\n",
        "\n",
        "ratings = (\n",
        "    spark.read\n",
        "    .option(\"header\", True)\n",
        "    .csv(\"file:///data/task3/cut_ratings.csv\")\n",
        "    .select(\n",
        "        F.col(\"user_uid\").cast(\"long\"),\n",
        "        F.col(\"element_uid\").cast(\"long\"),\n",
        "        F.col(\"rating\").cast(\"int\"),\n",
        "    )\n",
        ")\n",
        "\n",
        "user_ids = (\n",
        "    spark.read\n",
        "    .option(\"header\", True)\n",
        "    .csv(\"file:///data/task3/ids.csv\")\n",
        "    .select(F.col(\"user_uid\").cast(\"long\"))\n",
        ")\n",
        "\n",
        "transactions.show(5)\n",
        "ratings.show(5)\n",
        "user_ids.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0963ed4",
      "metadata": {
        "id": "a0963ed4"
      },
      "source": [
        "### Решение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31dac489",
      "metadata": {
        "id": "31dac489"
      },
      "outputs": [],
      "source": [
        "# Ваше решение в ячейках ниже ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40fc85fb",
      "metadata": {
        "id": "40fc85fb"
      },
      "outputs": [],
      "source": [
        "good_ratings = ratings.filter(F.col(\"rating\").isin([8, 9, 10])) ## фильтрация оценок с 7 < x <= 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "bd40363a",
      "metadata": {
        "id": "bd40363a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-----------+------------+------+\n",
            "|user_uid|element_uid|watched_time|rating|\n",
            "+--------+-----------+------------+------+\n",
            "|   61690|       1415|        7289|     8|\n",
            "|  566386|        747|       10979|     9|\n",
            "|  153993|       1912|        6942|    10|\n",
            "|  336070|       7987|        5434|     8|\n",
            "|  485006|       7789|        7097|     9|\n",
            "+--------+-----------+------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "joined = transactions.join(\n",
        "    F.broadcast(good_ratings),\n",
        "    on=[\"user_uid\", \"element_uid\"],\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "joined.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "afc522ca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+----------+----------+----------+----------+-----------+-----------+\n",
            "|user_uid|8_max_time|8_min_time|9_max_time|9_min_time|10_max_time|10_min_time|\n",
            "+--------+----------+----------+----------+----------+-----------+-----------+\n",
            "|  459856|      NULL|      NULL|      NULL|      NULL|       7799|       7799|\n",
            "|   40132|      NULL|      NULL|      NULL|      NULL|       7566|       7566|\n",
            "|  393270|      NULL|      NULL|     15287|     15287|       NULL|       NULL|\n",
            "|  116139|      NULL|      NULL|      NULL|      NULL|      32916|      32916|\n",
            "|  255354|      NULL|      NULL|      NULL|      NULL|        184|        184|\n",
            "|  426340|      NULL|      NULL|      NULL|      NULL|      15819|      15819|\n",
            "|  470763|      NULL|      NULL|      NULL|      NULL|       6868|       6868|\n",
            "|  217853|      NULL|      NULL|      NULL|      NULL|       7682|       7682|\n",
            "|  179448|      NULL|      NULL|      NULL|      NULL|       7902|       7902|\n",
            "|  196029|      NULL|      NULL|      NULL|      NULL|       7708|       7708|\n",
            "|  105182|      NULL|      NULL|      7656|      7656|       NULL|       NULL|\n",
            "|  215137|      NULL|      NULL|      NULL|      NULL|      11895|      11895|\n",
            "|  156388|      7677|      7677|      NULL|      NULL|       NULL|       NULL|\n",
            "|  257952|      NULL|      NULL|      7093|      7093|       NULL|       NULL|\n",
            "|  122965|      NULL|      NULL|      5990|      5990|       NULL|       NULL|\n",
            "|  116612|      NULL|      NULL|      NULL|      NULL|       7581|       7456|\n",
            "|  549163|      NULL|      NULL|      NULL|      NULL|       8120|       8120|\n",
            "|  151813|      NULL|      NULL|      NULL|      NULL|      11020|      10159|\n",
            "|  250722|      7738|      7738|      NULL|      NULL|       NULL|       NULL|\n",
            "|  587868|      NULL|      NULL|      7856|      7856|       NULL|       NULL|\n",
            "|  590037|      NULL|      NULL|     14048|     14048|      32661|       9191|\n",
            "|  125171|      NULL|      NULL|      NULL|      NULL|       7677|       4601|\n",
            "|   27563|      NULL|      NULL|      NULL|      NULL|       9092|       9092|\n",
            "|  444781|      NULL|      NULL|      NULL|      NULL|       8378|       8378|\n",
            "|   56964|      NULL|      NULL|       300|       300|        377|        377|\n",
            "|  189004|      NULL|      NULL|      7882|      7882|       NULL|       NULL|\n",
            "|  498672|      8363|      8363|      NULL|      NULL|       NULL|       NULL|\n",
            "|   90398|      NULL|      NULL|      NULL|      NULL|      23492|      23492|\n",
            "|  169522|      6208|      6208|      NULL|      NULL|       8378|       8378|\n",
            "|  518990|      7837|      7837|      NULL|      NULL|       NULL|       NULL|\n",
            "|  307749|      NULL|      NULL|      NULL|      NULL|       2410|       2410|\n",
            "|  313622|      7737|      7737|      NULL|      NULL|       NULL|       NULL|\n",
            "|  474087|      7781|      7781|      NULL|      NULL|       NULL|       NULL|\n",
            "|  104473|      NULL|      NULL|      NULL|      NULL|       7791|       7791|\n",
            "|  211901|      7626|      7626|      NULL|      NULL|       NULL|       NULL|\n",
            "|   16896|      NULL|      NULL|     31249|     31249|      16598|      16598|\n",
            "|  290826|      4089|      4089|      NULL|      NULL|       NULL|       NULL|\n",
            "|  407721|      NULL|      NULL|      NULL|      NULL|       6795|       6795|\n",
            "|  525537|      7710|      7710|      NULL|      NULL|       NULL|       NULL|\n",
            "|  438826|      NULL|      NULL|      7670|      7670|       5187|       5187|\n",
            "|  484936|      NULL|      NULL|      7676|      7676|       NULL|       NULL|\n",
            "|  299914|      NULL|      NULL|     16828|     16828|       NULL|       NULL|\n",
            "|   99044|      NULL|      NULL|      5756|      5756|       NULL|       NULL|\n",
            "|  333318|      7554|      7554|      NULL|      NULL|       NULL|       NULL|\n",
            "|  375564|      NULL|      NULL|      NULL|      NULL|       7802|       7802|\n",
            "|  591136|      NULL|      NULL|      NULL|      NULL|      15126|      15126|\n",
            "|  527236|      NULL|      NULL|      NULL|      NULL|       7590|       7590|\n",
            "|   92773|      NULL|      NULL|      NULL|      NULL|       7922|       7922|\n",
            "|  102613|      6184|      6184|      7470|      7470|       NULL|       NULL|\n",
            "|   84492|     17329|      7183|      NULL|      NULL|       NULL|       NULL|\n",
            "+--------+----------+----------+----------+----------+-----------+-----------+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pivoted = (\n",
        "    joined\n",
        "        .groupBy(\"user_uid\")\n",
        "        .pivot(\"rating\", [8, 9, 10])\n",
        "        .agg(\n",
        "            F.max(\"watched_time\").alias(\"max_time\"),\n",
        "            F.min(\"watched_time\").alias(\"min_time\")\n",
        "        )\n",
        ")\n",
        "\n",
        "pivoted.show(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7b18c594",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+----------+----------+----------+----------+-----------+-----------+\n",
            "|user_uid|8_max_time|8_min_time|9_max_time|9_min_time|10_max_time|10_min_time|\n",
            "+--------+----------+----------+----------+----------+-----------+-----------+\n",
            "|124821  |NULL      |NULL      |NULL      |NULL      |7271       |121        |\n",
            "|537222  |15013     |15013     |NULL      |NULL      |NULL       |NULL       |\n",
            "|107891  |5550      |93        |NULL      |NULL      |NULL       |NULL       |\n",
            "|571326  |NULL      |NULL      |NULL      |NULL      |NULL       |NULL       |\n",
            "|412991  |NULL      |NULL      |NULL      |NULL      |NULL       |NULL       |\n",
            "|110138  |11682     |11682     |5160      |5160      |8599       |4569       |\n",
            "|278352  |NULL      |NULL      |NULL      |NULL      |NULL       |NULL       |\n",
            "|24124   |16        |16        |2578      |1575      |NULL       |NULL       |\n",
            "|513130  |NULL      |NULL      |NULL      |NULL      |NULL       |NULL       |\n",
            "|97634   |6504      |6504      |NULL      |NULL      |NULL       |NULL       |\n",
            "|570263  |7963      |394       |1268      |1020      |NULL       |NULL       |\n",
            "|236064  |NULL      |NULL      |NULL      |NULL      |NULL       |NULL       |\n",
            "|83691   |NULL      |NULL      |NULL      |NULL      |NULL       |NULL       |\n",
            "|391301  |6044      |6044      |NULL      |NULL      |NULL       |NULL       |\n",
            "|345688  |NULL      |NULL      |NULL      |NULL      |NULL       |NULL       |\n",
            "|538289  |17632     |17632     |NULL      |NULL      |NULL       |NULL       |\n",
            "|334052  |NULL      |NULL      |NULL      |NULL      |NULL       |NULL       |\n",
            "|43752   |9115      |9115      |NULL      |NULL      |3437       |3437       |\n",
            "|453355  |NULL      |NULL      |NULL      |NULL      |NULL       |NULL       |\n",
            "|247177  |NULL      |NULL      |NULL      |NULL      |6387       |5810       |\n",
            "+--------+----------+----------+----------+----------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Exception happened during processing of request from ('127.0.0.1', 42684)\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/opt/conda/lib/python3.8/socketserver.py\", line 347, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/opt/conda/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/opt/conda/lib/python3.8/socketserver.py\", line 747, in __init__\n",
            "    self.handle()\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
            "    poll(accum_updates)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
            "    if self.rfile in r and func():\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
            "    num_updates = read_int(self.rfile)\n",
            "  File \"/opt/conda/lib/python3.8/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
            "    raise EOFError\n",
            "EOFError\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "final = user_ids.join(pivoted, on=\"user_uid\", how=\"left\")\n",
        "\n",
        "final.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2XvKj9uBUFSV",
      "metadata": {
        "id": "2XvKj9uBUFSV"
      },
      "source": [
        "# Задание 4\n",
        "\n",
        "## Входные данные\n",
        "\n",
        "1. Потоковые данные о транзакциях из Kafka\n",
        "2. Ивенты генерятся случайным образом, при помощи скрипта в директории task5/ или task4/ - они дублируются и структура одинаковая\n",
        "\n",
        "Важно: данные генерируются случайным образом, поэтому результат будет у всех разный, соответственно можно ловить в том числе простые анамалии, например, статистически значимое отклонение значения какого-либо атрибута\n",
        "\n",
        "## Что нужно сделать\n",
        "\n",
        "1. Обработать потоковые данные: чтение и обработка данных о транзакциях в реальном времени, преобразовать входящие данные в DataFrame\n",
        "2. Вычислить скользящее среднее значение суммы транзакций за последние 5 минут\n",
        "3. Определить аномалии: пометить проблемные транзакции, например, если значение суммы транзакции больше среднего значения суммы транзакций в 2 раза\n",
        "4. Вывести данные об аномальных транзакциях в консоль в режиме реального времени\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x9CZprENUIS1",
      "metadata": {
        "id": "x9CZprENUIS1"
      },
      "outputs": [
        {
          "ename": "PySparkRuntimeError",
          "evalue": "[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPySparkRuntimeError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m spark \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSpark streaming\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark://spark-master:7077\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.jars.packages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morg.apache.spark:spark-sql-kafka-0-10_2.13-3.5.3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.shuffle.partitions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menableHiveSupport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m     )\n\u001b[0;32m--> 201\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    204\u001b[0m         master,\n\u001b[1;32m    205\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[1;32m    216\u001b[0m     )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[0;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/java_gateway.py:107\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkRuntimeError(\n\u001b[1;32m    108\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJAVA_GATEWAY_EXITED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    109\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[1;32m    110\u001b[0m     )\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(conn_info_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m info:\n\u001b[1;32m    113\u001b[0m     gateway_port \u001b[38;5;241m=\u001b[39m read_int(info)\n",
            "\u001b[0;31mPySparkRuntimeError\u001b[0m: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number."
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .master(\"spark://spark-master:7077\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", False) \\\n",
        "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
        "    .config(\"spark.sql.sources.bucketing.enabled\", True) \\\n",
        "    .config(\"spark.executor.memory\", \"1g\") \\\n",
        "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3\") \\\n",
        "    .config(\"spark.driver.memory\", \"2g\") \\\n",
        "    .appName(\"hw1\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "APaLKSxYUIAP",
      "metadata": {
        "id": "APaLKSxYUIAP"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'spark' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
          ]
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "652eb974",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.sparkContext.getConf().get(\"spark.jars.packages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "954b2e67",
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'SparkContext' object has no attribute 'listJars'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistJars\u001b[49m()\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SparkContext' object has no attribute 'listJars'"
          ]
        }
      ],
      "source": [
        "spark.sparkContext.listJars()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9bbd61d6",
      "metadata": {},
      "outputs": [
        {
          "ename": "AnalysisException",
          "evalue": "Failed to find data source: kafka. Please deploy the application as per the deployment section of Structured Streaming + Kafka Integration Guide.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadStream\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkafka\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkafka.bootstrap.servers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkafka:29092\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubscribe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransactions_stream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/streaming/readwriter.py:304\u001b[0m, in \u001b[0;36mDataStreamReader.load\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mload(path))\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Failed to find data source: kafka. Please deploy the application as per the deployment section of Structured Streaming + Kafka Integration Guide."
          ]
        }
      ],
      "source": [
        "df = (\n",
        "    spark.readStream\n",
        "         .format(\"kafka\")\n",
        "         .option(\"kafka.bootstrap.servers\", \"kafka:29092\")\n",
        "         .option(\"subscribe\", \"transactions_stream\")\n",
        "         .load()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "GOdBFG1gUH2U",
      "metadata": {
        "id": "GOdBFG1gUH2U"
      },
      "outputs": [
        {
          "ename": "AnalysisException",
          "evalue": "Failed to find data source: kafka. Please deploy the application as per the deployment section of Structured Streaming + Kafka Integration Guide.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [14], line 20\u001b[0m\n\u001b[1;32m      8\u001b[0m event_schema \u001b[38;5;241m=\u001b[39m StructType([\n\u001b[1;32m      9\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransaction_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     10\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, LongType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     16\u001b[0m ])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 2. Читаем поток из Kafka\u001b[39;00m\n\u001b[1;32m     19\u001b[0m kafka_raw \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadStream\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkafka\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkafka.bootstrap.servers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkafka:29092\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubscribe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransactions_stream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# имя топика из генератора\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstartingOffsets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 3. Парсим value (JSON → столбцы)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m parsed \u001b[38;5;241m=\u001b[39m kafka_raw\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m     30\u001b[0m     F\u001b[38;5;241m.\u001b[39mfrom_json(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m), event_schema)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m )\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/sql/streaming/readwriter.py:304\u001b[0m, in \u001b[0;36mDataStreamReader.load\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mload(path))\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Failed to find data source: kafka. Please deploy the application as per the deployment section of Structured Streaming + Kafka Integration Guide."
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import (\n",
        "    StructType, StructField,\n",
        "    StringType, DoubleType, LongType\n",
        ")\n",
        "\n",
        "# 1. Описываем схему события\n",
        "event_schema = StructType([\n",
        "    StructField(\"transaction_id\", StringType(), True),\n",
        "    StructField(\"user_id\", LongType(), True),\n",
        "    StructField(\"timestamp\", StringType(), True),  # сначала строкой\n",
        "    StructField(\"amount\", DoubleType(), True),\n",
        "    StructField(\"currency\", StringType(), True),\n",
        "    StructField(\"transaction_type\", StringType(), True),\n",
        "    StructField(\"status\", StringType(), True),\n",
        "])\n",
        "\n",
        "# 2. Читаем поток из Kafka\n",
        "kafka_raw = (\n",
        "    spark.readStream\n",
        "         .format(\"kafka\")\n",
        "         .option(\"kafka.bootstrap.servers\", \"kafka:29092\")\n",
        "         .option(\"subscribe\", \"transactions_stream\")  # имя топика из генератора\n",
        "         .option(\"startingOffsets\", \"latest\")\n",
        "         .load()\n",
        ")\n",
        "\n",
        "# 3. Парсим value (JSON → столбцы)\n",
        "parsed = kafka_raw.select(\n",
        "    F.from_json(F.col(\"value\").cast(\"string\"), event_schema).alias(\"data\")\n",
        ").select(\"data.*\")\n",
        "\n",
        "# 4. Приводим timestamp к нормальному типу\n",
        "events = parsed.withColumn(\n",
        "    \"event_time\",\n",
        "    F.to_timestamp(\"timestamp\")\n",
        ").drop(\"timestamp\")\n",
        "\n",
        "events.printSchema()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m6ffVIImUcrx",
      "metadata": {
        "id": "m6ffVIImUcrx"
      },
      "source": [
        "# Задание 5\n",
        "\n",
        "**Входные данные**\n",
        "\n",
        "1. Вам будет предоставлен docker-compose файл. Отличный от инфраструкты для ДЗ№1 и предыдущих заданий этого ДЗ№2\n",
        "2. Генератор ивентов для топика кафки. Из этого топика нужно будет считывать данные\n",
        "3. Структура данных, которые будут поступать в топик\n",
        "4. Скорипт с генерацие ивентов их записью в Kafka Topic\n",
        "\n",
        "#### Описание входящих данных\n",
        "\n",
        "transaction_id — уникальный идентификатор транзакции\n",
        "user_id — идентификатор пользователя\n",
        "timestamp — время транзакции\n",
        "amount — сумма транзакции\n",
        "currency — валюта транзакции\n",
        "transaction_type — тип транзакции (покупка, возврат, снятие, пополнение)\n",
        "status — статус транзакции (успешно, неуспешно, в ожидании)\n",
        "\n",
        "**Что требуется сделать**\n",
        "\n",
        "Представьте, что вам поступила задача. Необходимо по рилтайм данным собрать витрины для аналитиков, к которым они могли бы обращаться, поверх которых они могли бы строить дашборды и многое другое.\n",
        "1. Ваша задача: перенести данные из контура Kafka в контур ClickHouse\n",
        "2. Построить несколько Kafka Engine таблиц (здесь на ваше усмотрение, можно одну, а можно и несколько)\n",
        "3. Учесть, что некоторые входящие данные содержать ошибки или могут не парситься и т д. Для решение этой проблемы необходимо реализовать deadletter механизм при помощи MV\n",
        "4. У вас должно быть минимум две таблицы MergeTree, они должны отличаться и быть логичными, то есть содержать какой-то смысл, иными словами – быть удобными для пользователя\n",
        "5. Необходимо приложить код кафка энжинов, код MV, код таблиц и скрины запросов и создания таблиц в ClickHouse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0QlNfgb0UlmC",
      "metadata": {
        "id": "0QlNfgb0UlmC"
      },
      "outputs": [],
      "source": [
        "# ваш код здесь ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6q9dLobqUnIm",
      "metadata": {
        "id": "6q9dLobqUnIm"
      },
      "outputs": [],
      "source": [
        "# ваши скрипты создания Kafka-Engine здесь ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jxUBzDc0VGkW",
      "metadata": {
        "id": "jxUBzDc0VGkW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l_hpZDzbUosn",
      "metadata": {
        "id": "l_hpZDzbUosn"
      },
      "outputs": [],
      "source": [
        "# ваши скрипты создания MV и MV DLQ здесь..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "koJWn-UgVH6r",
      "metadata": {
        "id": "koJWn-UgVH6r"
      },
      "outputs": [],
      "source": [
        "# ваши скрипты создания MergeTree таблиц здесь ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZL9IEiF9VjiK",
      "metadata": {
        "id": "ZL9IEiF9VjiK"
      },
      "outputs": [],
      "source": [
        "# ваш прочий Python-код для решения задачи / аналитики / EDA здесь ..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
